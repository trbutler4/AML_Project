{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from process_data import process\n",
    "from datasets import load_dataset, load_from_disk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset will be cached after loading the first time \n",
    "\n",
    "\n",
    "# try to load processed data from disk\n",
    "try:\n",
    "    train_ds = load_from_disk(\"data/train\")\n",
    "    test_ds = load_from_disk(\"data/test\")\n",
    "    \n",
    "except: \n",
    "    # this dataset has splits for training and testing already \n",
    "    ds = load_dataset(\"mwritescode/slither-audited-smart-contracts\", \"big-plain-text\")\n",
    "\n",
    "    # data processing done in process_data.py \n",
    "    train_ds, test_ds = process(ds)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': tensor([0.0022, 0.0022, 0.0000, 0.0411, 0.0000, 0.0281, 0.0000, 0.0043, 0.0022,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0043, 0.0173, 0.0173, 0.0000, 0.0022,\n",
       "         0.0000, 0.0130, 0.0108, 0.0043, 0.0130, 0.0043, 0.2078, 0.0000, 0.0087,\n",
       "         0.0000, 0.0000, 0.0000, 0.0152, 0.0433, 0.0693, 0.0584, 0.0043, 0.0281,\n",
       "         0.0000, 0.0000, 0.0087, 0.0411, 0.0000, 0.0000, 0.0000, 0.0022, 0.0476,\n",
       "         0.0000, 0.0108, 0.0000, 0.0000, 0.0238, 0.0065, 0.0000, 0.0022, 0.0000,\n",
       "         0.0000, 0.0000, 0.0065, 0.0043, 0.0000, 0.0000, 0.0000, 0.0000, 0.0065,\n",
       "         0.0000, 0.0022, 0.0065, 0.0022, 0.0000, 0.0000, 0.0411, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0065, 0.0043, 0.0022, 0.0000, 0.0130, 0.0108, 0.0000,\n",
       "         0.0022, 0.0000, 0.0022, 0.0152, 0.0498, 0.0000, 0.0000, 0.0000, 0.0043,\n",
       "         0.0000, 0.0000, 0.0087, 0.0628, 0.0000, 0.0000, 0.0000, 0.0022, 0.0000,\n",
       "         0.0022]),\n",
       " 'labels': tensor([0., 0.])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualizing the data after processing \n",
    "train_ds[0]\n",
    "# features represent frequency of a bigram appearing in the contract\n",
    "# labels represent whether a vulnerability was found"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definign input and output size\n",
    "input_size = len(train_ds[0]['features'])\n",
    "output_size = len(train_ds[0]['labels']) \n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, input_size//2)\n",
    "        self.layer2 = nn.Linear(input_size//2, output_size)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.0692 Accuracy: 0.8567492961883545\n",
      "Epoch [2/10], Loss: 0.6256 Accuracy: 0.8567492961883545\n",
      "Epoch [3/10], Loss: 0.6149 Accuracy: 0.8567492961883545\n",
      "Epoch [4/10], Loss: 0.6049 Accuracy: 0.8567492961883545\n",
      "Epoch [5/10], Loss: 0.5955 Accuracy: 0.8567492961883545\n",
      "Epoch [6/10], Loss: 0.5866 Accuracy: 0.8567492961883545\n",
      "Epoch [7/10], Loss: 0.5783 Accuracy: 0.8567492961883545\n",
      "Epoch [8/10], Loss: 0.5704 Accuracy: 0.8567492961883545\n",
      "Epoch [9/10], Loss: 0.5629 Accuracy: 0.8567492961883545\n",
      "Epoch [10/10], Loss: 0.5558 Accuracy: 0.8567492961883545\n"
     ]
    }
   ],
   "source": [
    "# Define the neural network\n",
    "model = Net()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy for multilabels\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# define data \n",
    "features = train_ds['features']\n",
    "labels = train_ds['labels']\n",
    "labels = torch.argmax(labels, dim=1)\n",
    "labels = F.one_hot(labels, num_classes=output_size).float()\n",
    "\n",
    "# define test data\n",
    "test_features = test_ds['features']\n",
    "test_labels = test_ds['labels']\n",
    "\n",
    "# Train the neural network\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(features)\n",
    "\n",
    "    # Calculate the loss\n",
    "    loss = criterion(output, labels)\n",
    "    \n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # check prediction \n",
    "    prediction = model(test_features)\n",
    "    prediction_loss = criterion(prediction, test_labels)\n",
    "    accuracy = (torch.argmax(prediction, 1 ) == torch.argmax(test_labels, 1)).float().mean() \n",
    "    # Print the loss\n",
    "    print('Epoch [{}/{}], Loss: {:.4f} Accuracy: {}'.format(epoch+1, num_epochs, loss.item(), accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
